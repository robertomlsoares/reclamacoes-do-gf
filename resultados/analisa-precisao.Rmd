---
title: "Análise da precisão"
output:
  html_document:
    df_print: paged
---

```{r}
library(tidyverse)
library(here)
library(modelr)
library(broom)

theme_set(theme_bw())
```

## Os dados

```{r carrega}
reclamacoes_raw = read_csv(here("data/reclamacoes-raw/reclamacoes-raw.csv"))
avaliacoes_raw = read_csv(here("data/avaliacoes/avaliacoes-20180222.csv"))
sentimentos = read_csv(here("data/sentimentos/sentimento.csv"))

reclamacoes_raw = reclamacoes_raw %>% 
    mutate(id = 1:n(), 
           comprimento_reclamacao = str_length(reclamacao), 
           nome_orgao = str_split(link, "/") %>% map_chr(~ .[[5]]))
```

`reclamacoes_l` tem um formato long em vez de wide (explicado [aqui](https://sejdemyr.github.io/r-tutorials/basics/wide-and-long/)).

```{r junta}
avaliacoes = avaliacoes_raw %>% 
    group_by(id_reclamação) %>% 
    summarise(insatisfação = median(insatisfação), 
              avaliadores = n())

reclamacoes = reclamacoes_raw %>% 
    inner_join(avaliacoes, by = c("id" = "id_reclamação")) %>% 
    left_join(sentimentos, by = "id")

reclamacoes_l = reclamacoes %>%  
    select(-palavras_op30, -palavras_sent) %>% 
    gather(key = "lexico", 
           value = "polaridade", 
           sentimento_op30, sentimento_sent)

# Adicionando variáveis utilizadas na exploração dos dados
# quantidade_palavas -> quantidade de palavras com pelo menos 2 caracteres. Lembrar que é diferente da variável que o analisador lexico retorna: palavras
# quantidade_caixa_alta -> quantidade de palavras com pelo menos 2 caracteres em que todas são caixa alta.

reclamacoes_l = reclamacoes_l %>%
    mutate(quantidade_caixa_alta = str_count(reclamacoes_l$reclamacao, "\\b[A-Z\u00C0-\u00DC]{2,}\\b"),
           quantidade_palavras = str_count(reclamacoes_l$reclamacao, "\\b[a-z\u00E0-\u00FCA-Z\u00C0-\u00DC]{2,}\\b"))

```

Converte polaridades para escala 0-5

```{r}
inverter <- function(x) { 
    return(-x)
}

normalizar <- function(x) {
    return(5 * ((x-min(x)) / (max(x) - min(x))))
}

reclamacoes_l = reclamacoes_l %>% 
    group_by(lexico) %>% 
    mutate(polaridade_normalizada = normalizar(inverter(polaridade)))
```

Calcula o erro por reclamação

```{r}
reclamacoes_l = reclamacoes_l %>% 
    mutate(erro = (insatisfação - polaridade_normalizada)**2)
```


## EDA

Inicial. Faça os gráficos a mais que achar necessário para entender os dados que temos de resultado.

```{r}
reclamacoes %>% 
    ggplot(aes(x = sentimento_op30, y = sentimento_sent)) + 
    geom_abline(slope = 1, intercept = 0, color = "grey") + 
    geom_count(alpha = .7) 
```

```{r}
reclamacoes_l %>% 
    ggplot(aes(x = insatisfação, y = polaridade_normalizada, group = insatisfação)) + 
    geom_jitter(alpha = .7)  + 
    facet_wrap(~ lexico)

reclamacoes_l %>% 
    ggplot(aes(x = insatisfação, y = erro, group = insatisfação)) + 
    geom_jitter(alpha = .5)  +
    # geom_boxplo() + 
    facet_wrap(~ lexico)
```


## Há relação entre o léxico e a precisão/erro?

Agora um modelo para responder sua pergunta.

```{r}
modelo <- lm(erro ~ lexico + palavras, data=reclamacoes_l)

tidy(modelo, conf.int = TRUE, conf.level = 0.95)

glance(modelo)
```

Regressão múltipla foi utilizada para analisar se o `lexico` e `palavras` tem uma associação significativa com o erro na estimativa de instatisfação da reclamação. Os resultados da regressão indicam que um modelo com os 2 preditores no formato Erro = -0.193686626*`lexico` + 0.004348164*`palavras` + 0.996724568 explicam 14,87% da variância da variável de resposta (R2 = 0.148749). `lexico`, medida como 0 se for o analizador léxico op30 ou 1 se for o léxico sent tem uma relação significativa com o erro (b = [-0.639301525;  0.25192827], IC com 95%), assim como `palavras` medida como quantidade de palavras que o lexico retornou (b = [0.003246448;  0.00544988], IC com 95%). O aumento de 1 unidade de `lexico` produz uma mudança de aproximadamente -0.19 no erro, já o aumento de 1 unidade de `palavras` produz uma mudança de aproximadamente 0.0043 no erro

```{r}
modelo <- lm(erro ~ lexico + quantidade_palavras, data=reclamacoes_l)

tidy(modelo, conf.int = TRUE, conf.level = 0.95)

glance(modelo)
```

Regressão múltipla foi utilizada para analisar se `lexico` e `quantidade_palavras` tem uma associação significativa com o erro na estimativa de instatisfação da reclamação. Os resultados da regressão indicam que um modelo com os 2 preditores no formato Erro = -0.193686626*`lexico` + 0.005087479*`quantidade_palavras` + 0.990114776 explicam 15.07% da variância da variável de resposta (R2 = 0.1507999). `lexico`, medida como/em [unidade ou o que é o 0 e o que é 1] tem uma relação significativa com o erro (b = [-0.638764414; 0.251391162], IC com 95%), assim como `quantidade_palavras` medida como quantidade de palavras com mais de 2 caracteres (b = [0.003808883;  0.006366075], IC com 95%). O aumento de 1 unidade de `lexico` produz uma mudança de aproximadamente -0.19 no erro, já um aumento de 1 unidade de `quantidade_palavras` produz uma mudança de aproximadamente 0.0051 no erro.

```{r}
modelo <- lm(erro ~ lexico + quantidade_caixa_alta, data=reclamacoes_l)

tidy(modelo, conf.int = TRUE, conf.level = 0.95)

glance(modelo)
```

Regressão múltipla foi utilizada para analisar se `lexico` e `quantidade_caixa_alta` tem uma associação com o erro na estimativa de instatisfação da reclamação. Os resultados da regressão indicam que um modelo com os 2 preditores no formato Erro = -0.193686626*`lexico` + 0.009903058*`quantidade_caixa_alta` + 1.589387718 explicam 1.5% da variância da variável de resposta (R2 = 0.01456559). `lexico`, medida como/em [unidade ou o que é o 0 e o que é 1] tem uma relação significativa com o erro (b = [-0.6731382061; 0.28576495], IC com 95%), assim como `quantidade_caixa_alta` medida como quantidade de palavras com mais de 2 caracteres em que todos os caracteres são maiusculos (b = [0.0007490953;  0.01905702], IC com 95%). O aumento de 1 unidade de `lexico` produz uma mudança de aproximadamente -0.19 no erro, já um aumento de 1 unidade de `quantidade_caixa_alta` produz uma mudança de aproximadamente 0.01 no erro.
